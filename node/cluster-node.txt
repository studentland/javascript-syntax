The "cluster" - creating child processes
that runs simultaneously and share the same server port.

Cluster module allows you to easily create child processes
that each runs on their own single thread, to handle the load.

A primary use case for the cluster module is networking.

Clusters of Node.js processes can be used to run multiple
instances of Node.js that can distribute workloads among
their application threads. When process isolation is not needed,
use the "worker_threads" module instead, which allows running
multiple application threads within a single Node.js instance.

Example:
"server.js"
const cluster = require('cluster');
const http = require('http');
const numCPUs = require('os').cpus().length;
const process = require('process');

if (cluster.isPrimary) {
  console.log(`Primary ${process.pid} is running`);

  // Fork workers.
  for (let i = 0; i < numCPUs; i++) { cluster.fork(); }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`worker ${worker.process.pid} died`);
  });
} else {
  // Workers can share any TCP connection
  // In this case it is an HTTP server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}

Terminal: $ node server.js
Output: Primary 3596 is running
Worker 4324 started
Worker 4520 started
Worker 6056 started
Worker 5644 started


https://nodejs.org/api/cluster.html#how-it-works
The worker processes are spawned using
the "child_process.fork()" method, so that they
can communicate with the parent via IPC
and pass server handles back and forth.

The cluster module supports two methods
of distributing incoming connections.

1 - round-robin approach, The primary process
listens on a port, accepts new connections and
distributes them across the workers, with some
built-in smarts to avoid overloading a worker process.

2 - The primary process creates the listen socket
and sends it to interested workers. The workers then
accept incoming connections directly.
In theory give the best perfomance.
On practice is not, due to OS scheduler vagaries.

Because server.listen() hands off most of the work
to the primary process, there are three cases where
the behavior between a normal Node.js process
and a cluster worker differs:
- server.listen({fd: 7}) Because the message is passed to the primary, file descriptor 7 in the parent will be listened on, and the handle passed to the worker, rather than listening to the worker's idea of what the number 7 file descriptor references.
- server.listen(handle) - explicitly will cause the worker to use
the supplied handle, rather than talk to the primary process.
- server.listen(0) Normally -> listen on a random port.
Cluster -> each worker receive same "random" port
each time of do listen(0). To listen on a unique port,
generate a port number based on the cluster worker ID.

Node.js does not provide routing logic. It is, therefore
important to design an application such that it does not
rely too heavily on in-memory data objects for
things like sessions and login.


Class: Worker <EventEmitter> - object contains all public
information and method about a worker.
In the primary it can be obtained using cluster.workers.
In a worker it can be obtained using cluster.worker.

Events:
'error', 'online'
but specific to this worker.
'exit' Callback params: ?worker<cluster.Worker>, code <number>, signal <string>
'listening': ?worker <cluster.Worker>, adress <Object>
'fork': worker <cluster.Worker>
'setup': settings <Object> -> emit if ".setupPrimary()" called



'message':
?worker <cluster.Worker>,
message <Object>,
handle <undefined> | <Object>



'disconnect': worker <cluster.Worker>
- similar to the cluster.on('disconnect') event,


Methods:

.disconnect() -> <cluster.Worker>

.disconnect([callback])
Calls .disconnect() on each worker in cluster.workers.
Callback <Function> Called when all workers
are disconnected and handles are closed.

.fork([env]) -> <cluster.Worker>. Spawn new worker process
- env <Object> Key/value pairs to add to worker process environment.
This can only be called from the primary process.


Props:

.exitedAfterDisconnect <boolean> -> true if exited due to
.kill() or .disconnect(). If exited other way -> false.
If worked still not exited -> undefined.

.isPrimary <boolean>
true If process.env.NODE_UNIQUE_ID is undefined.
.isWorker <boolean> true if not a primary

.id <number> - unique
.isConnected() <boolean> to its primary via its IPC channel
.isDead() <boolean> process has terminated by any command.
.process -> <ChildProcess>.fork() instance ref(used to create).
.schedulingPolicy

.setupPrimary([settings])
- settings <Object> cluster.settings bottom.

.settings -> <Object>. Readonly, autocreated with .setupPrimary() or .fork()
- .execArgv <string[]> Default: process.execArgv.
- .exec <string> worker file path. Default: process.argv[1].
- .args <string[]> arguments passed to worker. Default: process.argv.slice(2).
- .cwd <string> of the worker process.
Default: undefined (inherits from parent process).
- .serialization <string> 'json' and 'advanced'
- .silent <boolean> send output to parent's stdio. Default: false.
- .stdio <Array> configure stdio of forked processes.
Because the cluster module relies on IPC to function,
this configuration must contain an 'ipc' entry.
When this option is provided, it overrides silent.
- .uid <number>
- .gid <number>
- .inspectPort <number> | <Function> Sets inspector port of worker.
This can be a number, or a function that takes no arguments
and returns a number. By default each worker gets its own port,
incremented from the primary's process.debugPort.
- windowsHide <boolean>

Example:
const cluster = require('cluster');

cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'https'],
  silent: true
});
cluster.fork(); // https worker
cluster.setupPrimary({
  exec: 'worker.js',
  args: ['--use', 'http']
});
cluster.fork(); // http worker

This can only be called from the primary process.

.worker <Object> ref. to the current worker object.
Not available in the primary process.

.workers <Object>  stores the active worker objects,
keyed by id field. This makes it easy to loop through
all the workers. Available only in the primary process.

.kill([signal]): signal <string> is name of the kill signal to send
to the worker process. Default: 'SIGTERM'.

.send(message[, sendHandle[, options]][, callback]) -> <boolean>
- message <Object>
- sendHandle <Handle>
- options <Object> to parameterize sending of handles certain types
- callback <Function>
Send a message to a worker or primary, optionally with a handle.

